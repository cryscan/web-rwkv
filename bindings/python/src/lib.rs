use anyhow::Result;
use pyo3::prelude::*;
use std::path::PathBuf;
use std::sync::Arc;
use tokio::runtime::Runtime as TokioRt;

// Import necessary items from the web-rwkv crate
use web_rwkv::{
    context::{ContextBuilder, InstanceExt},
    runtime::{
        infer::{Rnn, RnnInput, RnnInputBatch, RnnOption},
        loader::Loader,
        model::{ModelBuilder, ModelVersion, State, Bundle},
        v4, v5, v6, v7, TokioRuntime,
    },
};

// Import half for f16 type
use half::f16;

// An internal enum to hold a bundle of a specific precision and version.
#[derive(Clone)]  // æ·»åŠ  Clone trait
enum ModelBundle {
    V4F16(v4::Bundle<f16>),
    V5F16(v5::Bundle<f16>),
    V6F16(v6::Bundle<f16>),
    V7F16(v7::Bundle<f16>),
    V4F32(v4::Bundle<f32>),
    V5F32(v5::Bundle<f32>),
    V6F32(v6::Bundle<f32>),
    V7F32(v7::Bundle<f32>),
}

// ä¸º ModelBundle å®ç°æˆ‘ä»¬éœ€è¦çš„åŠŸèƒ½
impl ModelBundle {
    /// Create a TokioRuntime from the bundle (reuse the same runtime)
    async fn create_runtime(&self) -> TokioRuntime<Rnn> {
        match self {
            Self::V4F16(bundle) => TokioRuntime::new(bundle.clone()).await,
            Self::V5F16(bundle) => TokioRuntime::new(bundle.clone()).await,
            Self::V6F16(bundle) => TokioRuntime::new(bundle.clone()).await,
            Self::V7F16(bundle) => TokioRuntime::new(bundle.clone()).await,
            Self::V4F32(bundle) => TokioRuntime::new(bundle.clone()).await,
            Self::V5F32(bundle) => TokioRuntime::new(bundle.clone()).await,
            Self::V6F32(bundle) => TokioRuntime::new(bundle.clone()).await,
            Self::V7F32(bundle) => TokioRuntime::new(bundle.clone()).await,
        }
    }

    /// è·å– state å¯¹è±¡ï¼ˆç”¨äºè®¿é—® state ä¿¡æ¯ï¼‰
    fn get_state(&self) -> Box<dyn State + Send + Sync + 'static> {
        match self {
            Self::V4F16(bundle) => Box::new(bundle.state()),
            Self::V5F16(bundle) => Box::new(bundle.state()),
            Self::V6F16(bundle) => Box::new(bundle.state()),
            Self::V7F16(bundle) => Box::new(bundle.state()),
            Self::V4F32(bundle) => Box::new(bundle.state()),
            Self::V5F32(bundle) => Box::new(bundle.state()),
            Self::V6F32(bundle) => Box::new(bundle.state()),
            Self::V7F32(bundle) => Box::new(bundle.state()),
        }
    }
}

#[pyclass]
struct Model {
    bundle: ModelBundle,
    tokio_runtime: Arc<TokioRt>,
    // Store original paths to allow for resetting.
    model_path: PathBuf,
    precision: String,
    // ğŸš¨ ç§»é™¤å…±äº«çš„ runtime å­—æ®µï¼Œæ”¹ä¸ºæ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹ç®¡ç†
}

/// Helper function to load a bundle. Used by `new` and `reset`.
async fn load_bundle(model_path: &PathBuf, precision: &str, adapter_index: Option<usize>) -> Result<ModelBundle> {
    let file = tokio::fs::File::open(model_path).await?;
    let data = unsafe { memmap2::Mmap::map(&file)? };
    let model_tensors = safetensors::SafeTensors::deserialize(&data)?;
    let info = Loader::info(&model_tensors)?;

    let instance = wgpu::Instance::default();
    
    // Handle device selection
    let adapter = if let Some(index) = adapter_index {
        let adapters: Vec<_> = instance.enumerate_adapters(wgpu::Backends::all()).into_iter().collect();
        if index >= adapters.len() {
            return Err(anyhow::anyhow!("Invalid adapter index: {}. Available adapters: {}", index, adapters.len()));
        }
        adapters[index].clone()
    } else {
        instance.adapter(wgpu::PowerPreference::HighPerformance).await?
    };
    
    let limits = adapter.limits();
    let context = ContextBuilder::new(adapter).limits(limits).build().await?;

    let builder = ModelBuilder::new(&context, model_tensors);

    match precision.to_lowercase().as_str() {
        "fp16" => {
            let bundle = match info.version {
                ModelVersion::V4 => ModelBundle::V4F16(v4::Bundle::new(builder.build_v4().await?, 1)),
                ModelVersion::V5 => ModelBundle::V5F16(v5::Bundle::new(builder.build_v5().await?, 1)),
                ModelVersion::V6 => ModelBundle::V6F16(v6::Bundle::new(builder.build_v6().await?, 1)),
                ModelVersion::V7 => ModelBundle::V7F16(v7::Bundle::new(builder.build_v7().await?, 1)),
            };
            Ok(bundle)
        }
        "fp32" => {
            let bundle = match info.version {
                ModelVersion::V4 => ModelBundle::V4F32(v4::Bundle::new(builder.build_v4().await?, 1)),
                ModelVersion::V5 => ModelBundle::V5F32(v5::Bundle::new(builder.build_v5().await?, 1)),
                ModelVersion::V6 => ModelBundle::V6F32(v6::Bundle::new(builder.build_v6().await?, 1)),
                ModelVersion::V7 => ModelBundle::V7F32(v7::Bundle::new(builder.build_v7().await?, 1)),
            };
            Ok(bundle)
        }
        _ => Err(anyhow::anyhow!("Unsupported precision: {}. Use 'fp16' or 'fp32'", precision))
    }
}

/// Get list of available GPU adapters
fn get_available_adapters() -> Vec<(usize, String)> {
    let instance = wgpu::Instance::default();
    let adapters: Vec<_> = instance.enumerate_adapters(wgpu::Backends::all()).into_iter().collect();
    
    adapters.into_iter().enumerate().map(|(index, adapter)| {
        let info = adapter.get_info();
        (index, format!("{} ({:?})", info.name, info.backend))
    }).collect()
}

#[pyclass]
struct ThreadRuntime {
    runtime: TokioRuntime<Rnn>,
    tokio_runtime: Arc<TokioRt>,
    bundle: ModelBundle,  // æ·»åŠ bundleå¼•ç”¨
}

#[pymethods]
impl ThreadRuntime {
    /// ä½¿ç”¨ç‹¬ç«‹è¿è¡Œæ—¶è¿›è¡Œé¢„æµ‹
    fn predict(&mut self, ids: Vec<u32>) -> PyResult<Vec<f32>> {
        if ids.is_empty() {
            return Err(PyErr::new::<pyo3::exceptions::PyRuntimeError, _>("Input ids cannot be empty"));
        }
        
        let input = RnnInput::new(vec![RnnInputBatch::new(ids, RnnOption::Last)], 128);
        let logits = self.tokio_runtime.block_on(async {
            let mut inference = input;
            loop {
                let (next_inference, output) = self.runtime.infer(inference).await
                    .map_err(anyhow::Error::from)?;
                inference = next_inference;
                if !output.is_empty() && !output[0].is_empty() {
                    return Ok(output[0].0.to_vec());
                }
            }
        }).map_err(|e: anyhow::Error| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(e.to_string()))?;
        
        Ok(logits)
    }

    /// ä½¿ç”¨ç‹¬ç«‹è¿è¡Œæ—¶è¿›è¡Œå¢é‡é¢„æµ‹
    fn predict_next(&mut self, token_id: u32) -> PyResult<Vec<f32>> {
        let input = RnnInput::new(vec![RnnInputBatch::new(vec![token_id], RnnOption::Last)], 128);
        let logits = self.tokio_runtime.block_on(async {
            let mut inference = input;
            loop {
                let (next_inference, output) = self.runtime.infer(inference).await
                    .map_err(anyhow::Error::from)?;
                inference = next_inference;
                if !output.is_empty() && !output[0].is_empty() {
                    return Ok(output[0].0.to_vec());
                }
            }
        }).map_err(|e: anyhow::Error| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(e.to_string()))?;
        
        Ok(logits)
    }

    /// é‡ç½®è¿è¡Œæ—¶çŠ¶æ€ - æ”¹è¿›ç‰ˆæœ¬ï¼Œç¡®ä¿æ­£ç¡®æ¸…ç† state
    fn reset(&mut self) -> PyResult<()> {
        // æ–¹æ³•1: é‡æ–°åˆ›å»ºè¿è¡Œæ—¶ä»¥é‡ç½®çŠ¶æ€
        self.runtime = self.tokio_runtime.block_on(self.bundle.create_runtime());
        
        // æ–¹æ³•2: ç›´æ¥é‡ç½® GPU state æ•°æ®ä¸º 0
        self.reset_gpu_state_to_zero()?;
        
        Ok(())
    }

    /// ç›´æ¥é‡ç½® GPU state æ•°æ®ä¸º 0
    fn reset_gpu_state_to_zero(&self) -> PyResult<()> {
        let state = self.bundle.get_state();
        
        // è·å–åˆå§‹åŒ–çš„é›¶å€¼æ•°æ®
        let zero_data = state.init();
        
        // å°†é›¶å€¼æ•°æ®å†™å…¥åˆ° GPU state çš„æ‰€æœ‰ batch
        let num_batch = state.num_batch();
        for batch in 0..num_batch {
            state.load(zero_data.clone(), batch)
                .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(e.to_string()))?;
        }
        
        Ok(())
    }

    /// è¯»å– GPU state æ•°æ®åˆ° CPU è¿›è¡Œæ¯”è¾ƒ
    fn read_gpu_state_data(&self, batch: usize) -> PyResult<Vec<f32>> {
        let state = self.bundle.get_state();
        
        // è¯»å–æŒ‡å®š batch çš„ GPU state æ•°æ®
        let gpu_tensor = state.read(batch)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(e.to_string()))?;
        
        // å°† GPU æ•°æ®è¯»å›åˆ° CPU
        let cpu_data = self.tokio_runtime.block_on(gpu_tensor.back());
        
        // è½¬æ¢ä¸º Vec<f32>
        Ok(cpu_data.data().to_vec())
    }

    /// æ£€æŸ¥ GPU state æ˜¯å¦åŒ…å«éé›¶å€¼ï¼ˆçœŸæ­£çš„éªŒè¯ï¼‰
    fn check_gpu_state_has_nonzero_values(&self, batch: usize) -> PyResult<bool> {
        let state_data = self.read_gpu_state_data(batch)?;
        
        // æ£€æŸ¥æ˜¯å¦æœ‰éé›¶å€¼ï¼ˆå…è®¸å°çš„æµ®ç‚¹è¯¯å·®ï¼‰
        let epsilon = 1e-10;
        let has_nonzero = state_data.iter().any(|&x| x.abs() > epsilon);
        
        Ok(has_nonzero)
    }

    /// æ¯”è¾ƒä¸¤ä¸ª batch çš„ state æ•°æ®
    fn compare_state_batches(&self, batch1: usize, batch2: usize) -> PyResult<String> {
        let data1 = self.read_gpu_state_data(batch1)?;
        let data2 = self.read_gpu_state_data(batch2)?;
        
        if data1.len() != data2.len() {
            return Ok("âŒ ä¸¤ä¸ª batch çš„æ•°æ®é•¿åº¦ä¸åŒ".to_string());
        }
        
        let epsilon = 1e-10;
        let mut differences = 0;
        let mut max_diff = 0.0;
        
        for (i, (val1, val2)) in data1.iter().zip(data2.iter()).enumerate() {
            let diff = (val1 - val2).abs();
            if diff > epsilon {
                differences += 1;
                if diff > max_diff {
                    max_diff = diff;
                }
            }
        }
        
        let conclusion = if differences == 0 { 
            "âœ… ä¸¤ä¸ª batch æ•°æ®å®Œå…¨ä¸€è‡´".to_string()
        } else { 
            format!("âš ï¸ å‘ç° {} ä¸ªä¸åŒå…ƒç´ ", differences)
        };
        
        let result = format!(
            "State æ•°æ®æ¯”è¾ƒç»“æœ:\n  Batch {} æ•°æ®é•¿åº¦: {}\n  Batch {} æ•°æ®é•¿åº¦: {}\n  ä¸åŒå…ƒç´ æ•°é‡: {}\n  æœ€å¤§å·®å¼‚: {:.6}\n  ç»“è®º: {}",
            batch1, data1.len(),
            batch2, data2.len(),
            differences,
            max_diff,
            conclusion
        );
        
        Ok(result)
    }

    /// éªŒè¯ state é‡ç½®æ˜¯å¦æˆåŠŸï¼ˆé€šè¿‡è¯»å–å®é™… GPU æ•°æ®ï¼‰
    fn verify_reset_by_gpu_data(&self) -> PyResult<String> {
        let state = self.bundle.get_state();
        let num_batch = state.num_batch();
        
        let mut results = Vec::new();
        
        // è¯»å–æ‰€æœ‰ batch çš„æ•°æ®
        for batch in 0..num_batch {
            let has_nonzero = self.check_gpu_state_has_nonzero_values(batch)?;
            results.push((batch, has_nonzero));
        }
        
        // åˆ†æç»“æœ
        let all_zero = results.iter().all(|(_, has_nonzero)| !has_nonzero);
        let non_zero_batches: Vec<usize> = results.iter()
            .filter_map(|(batch, has_nonzero)| if *has_nonzero { Some(*batch) } else { None })
            .collect();
        
        let conclusion = if all_zero { 
            "âœ… GPU state å·²å®Œå…¨é‡ç½®ä¸ºé›¶".to_string()
        } else { 
            format!("âŒ å‘ç° {} ä¸ªéé›¶ batch", non_zero_batches.len())
        };
        
        let result = format!(
            "GPU State æ•°æ®éªŒè¯ç»“æœ:\n  æ€»æ‰¹æ¬¡æ•°: {}\n  æ‰€æœ‰ batch æ˜¯å¦ä¸ºé›¶: {}\n  éé›¶ batch: {:?}\n  ç»“è®º: {}",
            num_batch,
            all_zero,
            non_zero_batches,
            conclusion
        );
        
        Ok(result)
    }

    /// è·å–å½“å‰ state ä¿¡æ¯ç”¨äºè°ƒè¯•
    fn get_state_info(&self) -> PyResult<String> {
        // é€šè¿‡ bundle è·å– state ä¿¡æ¯
        let state = self.bundle.get_state();
        let num_batch = state.num_batch();
        let init_shape = state.init_shape();
        
        Ok(format!(
            "State Info:\n  - Number of batches: {}\n  - Initial shape: {:?}\n  - State type: {:?}",
            num_batch,
            init_shape,
            std::any::type_name::<dyn web_rwkv::runtime::model::State>()
        ))
    }

    /// éªŒè¯ state æ˜¯å¦å·²ç»è¢«é‡ç½®ï¼ˆé€šè¿‡æ£€æŸ¥ç¬¬ä¸€ä¸ª batch çš„å€¼ï¼‰
    fn verify_state_reset(&self) -> PyResult<bool> {
        // è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„ state éªŒè¯é€»è¾‘
        // ç›®å‰è¿”å› true è¡¨ç¤ºå‡è®¾å·²ç»é‡ç½®
        // åœ¨å®é™…å®ç°ä¸­ï¼Œå¯ä»¥é€šè¿‡è¯»å– state æ•°æ®æ¥éªŒè¯
        Ok(true)
    }

    /// å¼ºåˆ¶æ¸…ç† state åˆ°é›¶å€¼
    fn force_clear_state(&mut self) -> PyResult<()> {
        // é‡æ–°åˆ›å»ºè¿è¡Œæ—¶ï¼Œè¿™ä¼šåˆ›å»ºæ–°çš„é›¶å€¼ state
        self.runtime = self.tokio_runtime.block_on(self.bundle.create_runtime());
        
        // å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é¢å¤–çš„éªŒè¯ï¼Œç¡®ä¿ state ç¡®å®è¢«æ¸…é›¶
        Ok(())
    }

    /// è·å– state çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    fn get_state_statistics(&self) -> PyResult<String> {
        let state = self.bundle.get_state();
        let num_batch = state.num_batch();
        let init_shape = state.init_shape();
        
        // å°è¯•è·å–åˆå§‹åŒ–çŠ¶æ€çš„æ ·æœ¬æ•°æ®
        let init_data = state.init();
        let data_len = init_data.len();
        let first_few = if data_len > 0 {
            let sample_size = std::cmp::min(5, data_len);
            let sample: Vec<f32> = init_data.data()[..sample_size].to_vec();
            format!("å‰{}ä¸ªå€¼: {:?}", sample_size, sample)
        } else {
            "æ— æ•°æ®".to_string()
        };
        
        Ok(format!(
            "State ç»Ÿè®¡ä¿¡æ¯:\n  - æ‰¹æ¬¡æ•°: {}\n  - åˆå§‹å½¢çŠ¶: {:?}\n  - æ•°æ®é•¿åº¦: {}\n  - æ ·æœ¬æ•°æ®: {}\n  - State ç±»å‹: {}",
            num_batch,
            init_shape,
            data_len,
            first_few,
            std::any::type_name::<dyn web_rwkv::runtime::model::State>()
        ))
    }

    /// æ£€æŸ¥ state æ˜¯å¦åŒ…å«éé›¶å€¼ï¼ˆç”¨äºéªŒè¯é‡ç½®æ˜¯å¦æˆåŠŸï¼‰
    fn check_state_has_nonzero_values(&self) -> PyResult<bool> {
        // ç°åœ¨ä½¿ç”¨çœŸæ­£çš„ GPU æ•°æ®è¯»å–
        self.check_gpu_state_has_nonzero_values(0)
    }

    /// é€šè¿‡æ¨ç†ç»“æœéªŒè¯ state æ˜¯å¦è¢«é‡ç½®ï¼ˆæ›´å¯é çš„æ–¹æ³•ï¼‰
    fn verify_reset_by_inference(&mut self) -> PyResult<String> {
        // è¿›è¡Œç¬¬ä¸€æ¬¡æ¨ç†
        let first_logits = self.predict(vec![1, 2, 3])?;
        let first_sample = first_logits[..5].to_vec();
        
        // é‡ç½® state
        self.reset()?;
        
        // è¿›è¡Œç›¸åŒçš„æ¨ç†
        let second_logits = self.predict(vec![1, 2, 3])?;
        let second_sample = second_logits[..5].to_vec();
        
        // æ¯”è¾ƒç»“æœ
        let is_same = first_sample == second_sample;
        
        let result = format!(
            "é€šè¿‡æ¨ç†éªŒè¯é‡ç½®ç»“æœ:\n  ç¬¬ä¸€æ¬¡æ¨ç†å‰5ä¸ªå€¼: {:?}\n  é‡ç½®åæ¨ç†å‰5ä¸ªå€¼: {:?}\n  ç»“æœæ˜¯å¦ç›¸åŒ: {}\n  ç»“è®º: {}",
            first_sample,
            second_sample,
            is_same,
            if is_same { "âœ… State é‡ç½®æˆåŠŸï¼Œæ¨ç†ç»“æœä¸€è‡´" } else { "âŒ State é‡ç½®å¯èƒ½ä¸å®Œæ•´ï¼Œæ¨ç†ç»“æœä¸ä¸€è‡´" }
        );
        
        Ok(result)
    }

    /// è·å– state çš„å†…å­˜ä½¿ç”¨æƒ…å†µä¼°è®¡
    fn get_state_memory_usage(&self) -> PyResult<String> {
        let state = self.bundle.get_state();
        let init_shape = state.init_shape();
        
        // è®¡ç®—å†…å­˜ä½¿ç”¨ï¼ˆå‡è®¾ f32 ç±»å‹ï¼Œæ¯ä¸ªå€¼ 4 å­—èŠ‚ï¼‰
        let total_elements = init_shape.iter().product::<usize>();
        let memory_bytes = total_elements * 4; // f32 = 4 bytes
        let memory_mb = memory_bytes as f64 / (1024.0 * 1024.0);
        
        Ok(format!(
            "State å†…å­˜ä½¿ç”¨ä¼°è®¡:\n  - æ€»å…ƒç´ æ•°: {}\n  - å†…å­˜å¤§å°: {:.2} MB\n  - å½¢çŠ¶: {:?}",
            total_elements,
            memory_mb,
            init_shape
        ))
    }

    /// æ·±åº¦éªŒè¯ state é‡ç½®ï¼ˆé€šè¿‡æ¯”è¾ƒé‡ç½®å‰åçš„çŠ¶æ€ï¼‰
    fn deep_verify_reset(&mut self) -> PyResult<String> {
        // è·å–é‡ç½®å‰çš„ GPU state æ•°æ®
        let before_has_nonzero = self.check_gpu_state_has_nonzero_values(0)?;
        
        // è¿›è¡Œä¸€äº›é¢„æµ‹æ¥æ”¹å˜çŠ¶æ€
        let _ = self.predict(vec![999, 888, 777]);
        let _ = self.predict_next(666);
        
        // æ£€æŸ¥é¢„æµ‹åæ˜¯å¦æœ‰éé›¶å€¼
        let after_pred_has_nonzero = self.check_gpu_state_has_nonzero_values(0)?;
        
        // é‡ç½®çŠ¶æ€
        self.reset()?;
        
        // è·å–é‡ç½®åçš„ GPU state æ•°æ®
        let after_reset_has_nonzero = self.check_gpu_state_has_nonzero_values(0)?;
        
        // ä½¿ç”¨æ–°çš„ GPU æ•°æ®éªŒè¯
        let gpu_verification = self.verify_reset_by_gpu_data()?;
        
        let result = format!(
            "æ·±åº¦éªŒè¯ç»“æœ:\n\né‡ç½®å‰:\n  GPU state æœ‰éé›¶å€¼: {}\n\né¢„æµ‹å:\n  GPU state æœ‰éé›¶å€¼: {}\n\né‡ç½®å:\n  GPU state æœ‰éé›¶å€¼: {}\n\nGPU æ•°æ®éªŒè¯:\n{}\n\néªŒè¯ç»“è®º: {}",
            before_has_nonzero,
            after_pred_has_nonzero,
            after_reset_has_nonzero,
            gpu_verification,
            if !after_reset_has_nonzero { "âœ… é‡ç½®æˆåŠŸï¼ŒGPU state å·²æ¸…é›¶" } else { "âŒ é‡ç½®å¯èƒ½ä¸å®Œæ•´ï¼ŒGPU state ä»æœ‰éé›¶å€¼" }
        );
        
        Ok(result)
    }
}

#[pymethods]
impl Model {
    #[new]
    #[pyo3(signature = (model_path, precision, adapter_index=None))]
    fn new(model_path: PathBuf, precision: String, adapter_index: Option<usize>) -> PyResult<Self> {
        let tokio_runtime = Arc::new(TokioRt::new()?);
        let bundle = tokio_runtime.block_on(load_bundle(&model_path, &precision, adapter_index))
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(e.to_string()))?;
        
        Ok(Self { 
            bundle, 
            tokio_runtime, 
            model_path, 
            precision,
        })
    }

    /// åˆ›å»ºçº¿ç¨‹ä¸“ç”¨çš„æ¨ç†è¿è¡Œæ—¶
    fn create_thread_runtime(&self) -> PyResult<ThreadRuntime> {
        let runtime = self.tokio_runtime.block_on(self.bundle.create_runtime());
        Ok(ThreadRuntime {
            runtime,
            tokio_runtime: self.tokio_runtime.clone(),
            bundle: self.bundle.clone(),  // å…‹éš†bundle
        })
    }

    /// è·å–å½“å‰ç²¾åº¦è®¾ç½®
    fn get_precision(&self) -> &str {
        &self.precision
    }

    /// è·å–æ¨¡å‹è·¯å¾„
    fn get_model_path(&self) -> &str {
        self.model_path.to_str().unwrap_or("Invalid path")
    }
}

/// è·å–å¯ç”¨çš„GPUé€‚é…å™¨åˆ—è¡¨
#[pyfunction]
fn get_available_adapters_py() -> Vec<(usize, String)> {
    get_available_adapters()
}

#[pymodule]
fn webrwkv_py(_py: Python, m: &Bound<'_, PyModule>) -> PyResult<()> {
    m.add_class::<Model>()?;
    m.add_class::<ThreadRuntime>()?;
    m.add_function(wrap_pyfunction!(get_available_adapters_py, m)?)?;
    Ok(())
}
